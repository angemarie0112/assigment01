{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGU7Rp6wRdvF",
        "outputId": "e5f5aeb8-7c8b-4e3f-e39b-88c2c313d660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkgFgbo6Uag_",
        "outputId": "4dc686ea-0507-4b7d-d755-760fc97c95fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1557 documents\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/drive/My Drive/small_docs/'\n",
        "#folder_path = '/content/drive/My Drive/larges_docs/full_docs/'\n",
        "\n",
        "documents = []\n",
        "\n",
        "# Iterating through all text files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "            documents.append(content)\n",
        "\n",
        "print(f\"Loaded {len(documents)} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnRxGMfjjw1O",
        "outputId": "14eeb691-814c-48b5-f4fc-f8f16a563ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inverted index with positions saved at: /content/drive/My Drive/inverted_index.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import json\n",
        "\n",
        "# Download necessary NLTK packages\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialize the stemmer and stopwords\n",
        "stemmer = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Define the full preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Step 1: Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Step 2: Case Formatting (lowercasing)\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # Step 3: Removing punctuation (keeping only alphanumeric tokens)\n",
        "    tokens = [word for word in tokens if word.isalnum()]\n",
        "\n",
        "    # Step 4: Stopword Removal\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Step 5: Stemming (reducing words to base forms)\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "original_directory = '/content/drive/My Drive/small_docs/'\n",
        "#original_directory = '/content/drive/My Drive/larges_docs/full_docs/'\n",
        "\n",
        "# Create the inverted index dictionary\n",
        "inverted_index = {}\n",
        "\n",
        "# Get a list of only the text files in the original directory\n",
        "original_filenames = sorted([filename for filename in os.listdir(original_directory) if filename.endswith(\".txt\")])\n",
        "\n",
        "# Build the inverted index\n",
        "for doc_id, filename in enumerate(original_filenames):\n",
        "    file_path = os.path.join(original_directory, filename)\n",
        "\n",
        "    # Read the content of the document\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "\n",
        "        # Apply full preprocessing pipeline to the content\n",
        "        tokens = preprocess_text(content)\n",
        "\n",
        "        # Populate the inverted index with positions\n",
        "        for pos, token in enumerate(tokens):\n",
        "            if token not in inverted_index:\n",
        "                inverted_index[token] = {filename: [pos]}\n",
        "            else:\n",
        "                if filename not in inverted_index[token]:\n",
        "                    inverted_index[token][filename] = [pos]\n",
        "                else:\n",
        "                    inverted_index[token][filename].append(pos)\n",
        "\n",
        "# Save the inverted index as a JSON file\n",
        "inverted_index_path = '/content/drive/My Drive/inverted_index.json'\n",
        "#inverted_index_path = '/content/drive/My Drive/larges_docs/inverted_index.json'\n",
        "with open(inverted_index_path, 'w', encoding='utf-8') as index_file:\n",
        "    json.dump(inverted_index, index_file, indent=4)\n",
        "\n",
        "print(f\"Inverted index with positions saved at: {inverted_index_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MLCUns47Jwe",
        "outputId": "f5317d22-6c34-49eb-c08d-37629c07a224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents matching the query 'types of road hugger tires': {'output_80.txt'}\n"
          ]
        }
      ],
      "source": [
        "def search_inverted_index(query, inverted_index):\n",
        "    # Preprocess the query (tokenize, lowercase, remove stopwords, etc.)\n",
        "    query_tokens = preprocess_text(query)\n",
        "\n",
        "    # Find documents matching each query token\n",
        "    result_docs = []\n",
        "    for token in query_tokens:\n",
        "        if token in inverted_index:\n",
        "            result_docs.append(set(inverted_index[token]))\n",
        "\n",
        "    if result_docs:\n",
        "        relevant_docs = set.intersection(*result_docs)\n",
        "        return relevant_docs\n",
        "    else:\n",
        "        return set()\n",
        "query = \"types of road hugger tires\"\n",
        "\n",
        "\n",
        "inverted_index_path = '/content/drive/My Drive/inverted_index.json'\n",
        "\n",
        "with open(inverted_index_path, 'r', encoding='utf-8') as file:\n",
        "    inverted_index = json.load(file)\n",
        "\n",
        "results = search_inverted_index(query, inverted_index)\n",
        "\n",
        "if results:\n",
        "    print(f\"Documents matching the query '{query}': {results}\")\n",
        "else:\n",
        "    print(f\"No documents found for the query '{query}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99eTxmrW5Gbv",
        "outputId": "74da9591-b0b1-4548-8b0c-2cfd2b35f87a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked documents for the query 'types of road hugger tires':\n",
            "output_590.txt: 0.3556\n",
            "output_965.txt: 0.3289\n",
            "output_58.txt: 0.2692\n",
            "output_655.txt: 0.1979\n",
            "output_483.txt: 0.1921\n",
            "output_171.txt: 0.1907\n",
            "output_1220.txt: 0.1853\n",
            "output_842.txt: 0.1775\n",
            "output_38.txt: 0.1771\n",
            "output_986.txt: 0.1755\n",
            "output_203.txt: 0.1697\n",
            "output_1256.txt: 0.1692\n",
            "output_1287.txt: 0.1579\n",
            "output_1174.txt: 0.1556\n",
            "output_650.txt: 0.1538\n",
            "output_1176.txt: 0.1532\n",
            "output_911.txt: 0.1451\n",
            "output_1369.txt: 0.1440\n",
            "output_544.txt: 0.1431\n",
            "output_1445.txt: 0.1427\n",
            "output_1038.txt: 0.1402\n",
            "output_352.txt: 0.1392\n",
            "output_35.txt: 0.1339\n",
            "output_649.txt: 0.1338\n",
            "output_1467.txt: 0.1332\n",
            "output_1207.txt: 0.1301\n",
            "output_1520.txt: 0.1275\n",
            "output_488.txt: 0.1247\n",
            "output_622.txt: 0.1232\n",
            "output_880.txt: 0.1225\n",
            "output_560.txt: 0.1220\n",
            "output_943.txt: 0.1217\n",
            "output_469.txt: 0.1212\n",
            "output_1326.txt: 0.1191\n",
            "output_80.txt: 0.1187\n",
            "output_971.txt: 0.1185\n",
            "output_1453.txt: 0.1160\n",
            "output_966.txt: 0.1140\n",
            "output_930.txt: 0.1138\n",
            "output_674.txt: 0.1135\n",
            "output_1239.txt: 0.1125\n",
            "output_345.txt: 0.1122\n",
            "output_1146.txt: 0.1117\n",
            "output_1166.txt: 0.1114\n",
            "output_1499.txt: 0.1107\n",
            "output_390.txt: 0.1102\n",
            "output_300.txt: 0.1098\n",
            "output_1139.txt: 0.1091\n",
            "output_76.txt: 0.1076\n",
            "output_1531.txt: 0.1068\n",
            "output_1382.txt: 0.1067\n",
            "output_186.txt: 0.1054\n",
            "output_1458.txt: 0.1052\n",
            "output_1084.txt: 0.1042\n",
            "output_220.txt: 0.1040\n",
            "output_1405.txt: 0.1032\n",
            "output_1478.txt: 0.1024\n",
            "output_1267.txt: 0.1019\n",
            "output_829.txt: 0.1019\n",
            "output_983.txt: 0.1018\n",
            "output_1409.txt: 0.1017\n",
            "output_137.txt: 0.1005\n",
            "output_450.txt: 0.1004\n",
            "output_348.txt: 0.1000\n",
            "output_294.txt: 0.0997\n",
            "output_1060.txt: 0.0993\n",
            "output_1151.txt: 0.0993\n",
            "output_1100.txt: 0.0972\n",
            "output_1489.txt: 0.0966\n",
            "output_518.txt: 0.0960\n",
            "output_714.txt: 0.0959\n",
            "output_1530.txt: 0.0956\n",
            "output_301.txt: 0.0948\n",
            "output_1375.txt: 0.0946\n",
            "output_376.txt: 0.0943\n",
            "output_341.txt: 0.0941\n",
            "output_11.txt: 0.0941\n",
            "output_1529.txt: 0.0938\n",
            "output_644.txt: 0.0933\n",
            "output_898.txt: 0.0927\n",
            "output_1398.txt: 0.0924\n",
            "output_618.txt: 0.0916\n",
            "output_1127.txt: 0.0911\n",
            "output_1244.txt: 0.0908\n",
            "output_688.txt: 0.0900\n",
            "output_1188.txt: 0.0898\n",
            "output_91.txt: 0.0896\n",
            "output_104.txt: 0.0895\n",
            "output_680.txt: 0.0894\n",
            "output_799.txt: 0.0893\n",
            "output_1438.txt: 0.0892\n",
            "output_280.txt: 0.0890\n",
            "output_624.txt: 0.0871\n",
            "output_1149.txt: 0.0867\n",
            "output_595.txt: 0.0859\n",
            "output_1372.txt: 0.0859\n",
            "output_1461.txt: 0.0855\n",
            "output_445.txt: 0.0853\n",
            "output_1407.txt: 0.0847\n",
            "output_447.txt: 0.0847\n",
            "output_498.txt: 0.0840\n",
            "output_791.txt: 0.0836\n",
            "output_1380.txt: 0.0836\n",
            "output_581.txt: 0.0833\n",
            "output_1154.txt: 0.0831\n",
            "output_1283.txt: 0.0828\n",
            "output_431.txt: 0.0827\n",
            "output_309.txt: 0.0825\n",
            "output_715.txt: 0.0817\n",
            "output_1354.txt: 0.0813\n",
            "output_507.txt: 0.0810\n",
            "output_853.txt: 0.0803\n",
            "output_1548.txt: 0.0802\n",
            "output_1550.txt: 0.0799\n",
            "output_1261.txt: 0.0797\n",
            "output_654.txt: 0.0795\n",
            "output_1554.txt: 0.0791\n",
            "output_597.txt: 0.0791\n",
            "output_1082.txt: 0.0788\n",
            "output_566.txt: 0.0781\n",
            "output_718.txt: 0.0779\n",
            "output_329.txt: 0.0777\n",
            "output_741.txt: 0.0777\n",
            "output_700.txt: 0.0774\n",
            "output_82.txt: 0.0774\n",
            "output_1090.txt: 0.0774\n",
            "output_1092.txt: 0.0772\n",
            "output_533.txt: 0.0772\n",
            "output_1051.txt: 0.0772\n",
            "output_994.txt: 0.0770\n",
            "output_1492.txt: 0.0766\n",
            "output_175.txt: 0.0764\n",
            "output_482.txt: 0.0764\n",
            "output_253.txt: 0.0759\n",
            "output_626.txt: 0.0758\n",
            "output_103.txt: 0.0754\n",
            "output_373.txt: 0.0753\n",
            "output_958.txt: 0.0751\n",
            "output_1074.txt: 0.0751\n",
            "output_909.txt: 0.0751\n",
            "output_1235.txt: 0.0751\n",
            "output_695.txt: 0.0747\n",
            "output_1026.txt: 0.0745\n",
            "output_979.txt: 0.0745\n",
            "output_1503.txt: 0.0744\n",
            "output_961.txt: 0.0742\n",
            "output_1156.txt: 0.0741\n",
            "output_870.txt: 0.0737\n",
            "output_952.txt: 0.0733\n",
            "output_1241.txt: 0.0728\n",
            "output_138.txt: 0.0725\n",
            "output_1131.txt: 0.0724\n",
            "output_1314.txt: 0.0720\n",
            "output_346.txt: 0.0720\n",
            "output_239.txt: 0.0716\n",
            "output_664.txt: 0.0712\n",
            "output_99.txt: 0.0712\n",
            "output_858.txt: 0.0710\n",
            "output_140.txt: 0.0709\n",
            "output_221.txt: 0.0707\n",
            "output_141.txt: 0.0706\n",
            "output_266.txt: 0.0705\n",
            "output_974.txt: 0.0704\n",
            "output_1069.txt: 0.0704\n",
            "output_1282.txt: 0.0702\n",
            "output_79.txt: 0.0702\n",
            "output_1009.txt: 0.0702\n",
            "output_281.txt: 0.0701\n",
            "output_205.txt: 0.0697\n",
            "output_900.txt: 0.0697\n",
            "output_459.txt: 0.0696\n",
            "output_515.txt: 0.0696\n",
            "output_668.txt: 0.0695\n",
            "output_1444.txt: 0.0694\n",
            "output_1388.txt: 0.0693\n",
            "output_1360.txt: 0.0693\n",
            "output_978.txt: 0.0688\n",
            "output_836.txt: 0.0686\n",
            "output_1419.txt: 0.0682\n",
            "output_1215.txt: 0.0681\n",
            "output_435.txt: 0.0680\n",
            "output_1340.txt: 0.0680\n",
            "output_1150.txt: 0.0679\n",
            "output_1435.txt: 0.0678\n",
            "output_1144.txt: 0.0678\n",
            "output_1182.txt: 0.0676\n",
            "output_830.txt: 0.0675\n",
            "output_401.txt: 0.0672\n",
            "output_940.txt: 0.0672\n",
            "output_1087.txt: 0.0670\n",
            "output_652.txt: 0.0669\n",
            "output_310.txt: 0.0669\n",
            "output_433.txt: 0.0667\n",
            "output_1428.txt: 0.0666\n",
            "output_991.txt: 0.0659\n",
            "output_514.txt: 0.0652\n",
            "output_973.txt: 0.0649\n",
            "output_296.txt: 0.0648\n",
            "output_538.txt: 0.0647\n",
            "output_881.txt: 0.0642\n",
            "output_692.txt: 0.0641\n",
            "output_891.txt: 0.0639\n",
            "output_682.txt: 0.0637\n",
            "output_1505.txt: 0.0634\n",
            "output_697.txt: 0.0634\n",
            "output_932.txt: 0.0633\n",
            "output_1540.txt: 0.0633\n",
            "output_226.txt: 0.0632\n",
            "output_846.txt: 0.0629\n",
            "output_1247.txt: 0.0625\n",
            "output_924.txt: 0.0624\n",
            "output_1292.txt: 0.0624\n",
            "output_555.txt: 0.0622\n",
            "output_240.txt: 0.0622\n",
            "output_936.txt: 0.0620\n",
            "output_1320.txt: 0.0619\n",
            "output_1014.txt: 0.0618\n",
            "output_491.txt: 0.0618\n",
            "output_1195.txt: 0.0617\n",
            "output_614.txt: 0.0615\n",
            "output_1362.txt: 0.0615\n",
            "output_12.txt: 0.0614\n",
            "output_754.txt: 0.0614\n",
            "output_252.txt: 0.0611\n",
            "output_1309.txt: 0.0610\n",
            "output_436.txt: 0.0609\n",
            "output_340.txt: 0.0606\n",
            "output_602.txt: 0.0606\n",
            "output_1052.txt: 0.0599\n",
            "output_15.txt: 0.0598\n",
            "output_1177.txt: 0.0597\n",
            "output_800.txt: 0.0597\n",
            "output_1263.txt: 0.0596\n",
            "output_951.txt: 0.0591\n",
            "output_647.txt: 0.0589\n",
            "output_1417.txt: 0.0586\n",
            "output_88.txt: 0.0586\n",
            "output_1257.txt: 0.0584\n",
            "output_532.txt: 0.0582\n",
            "output_202.txt: 0.0581\n",
            "output_693.txt: 0.0579\n",
            "output_1064.txt: 0.0579\n",
            "output_847.txt: 0.0576\n",
            "output_305.txt: 0.0575\n",
            "output_737.txt: 0.0575\n",
            "output_127.txt: 0.0574\n",
            "output_1102.txt: 0.0571\n",
            "output_465.txt: 0.0571\n",
            "output_554.txt: 0.0570\n",
            "output_1322.txt: 0.0568\n",
            "output_917.txt: 0.0564\n",
            "output_21.txt: 0.0564\n",
            "output_251.txt: 0.0563\n",
            "output_1393.txt: 0.0562\n",
            "output_421.txt: 0.0558\n",
            "output_571.txt: 0.0557\n",
            "output_990.txt: 0.0557\n",
            "output_1447.txt: 0.0555\n",
            "output_417.txt: 0.0552\n",
            "output_957.txt: 0.0552\n",
            "output_893.txt: 0.0549\n",
            "output_231.txt: 0.0547\n",
            "output_1533.txt: 0.0545\n",
            "output_194.txt: 0.0544\n",
            "output_1099.txt: 0.0543\n",
            "output_316.txt: 0.0543\n",
            "output_159.txt: 0.0542\n",
            "output_1507.txt: 0.0540\n",
            "output_495.txt: 0.0540\n",
            "output_1042.txt: 0.0535\n",
            "output_46.txt: 0.0535\n",
            "output_672.txt: 0.0535\n",
            "output_762.txt: 0.0534\n",
            "output_353.txt: 0.0532\n",
            "output_1171.txt: 0.0529\n",
            "output_492.txt: 0.0527\n",
            "output_913.txt: 0.0527\n",
            "output_792.txt: 0.0525\n",
            "output_1140.txt: 0.0525\n",
            "output_87.txt: 0.0525\n",
            "output_992.txt: 0.0524\n",
            "output_1355.txt: 0.0521\n",
            "output_162.txt: 0.0519\n",
            "output_485.txt: 0.0518\n",
            "output_1525.txt: 0.0515\n",
            "output_270.txt: 0.0511\n",
            "output_1114.txt: 0.0507\n",
            "output_1202.txt: 0.0505\n",
            "output_388.txt: 0.0505\n",
            "output_264.txt: 0.0502\n",
            "output_601.txt: 0.0500\n",
            "output_586.txt: 0.0499\n",
            "output_1343.txt: 0.0499\n",
            "output_834.txt: 0.0499\n",
            "output_244.txt: 0.0493\n",
            "output_645.txt: 0.0492\n",
            "output_355.txt: 0.0492\n",
            "output_918.txt: 0.0492\n",
            "output_1522.txt: 0.0488\n",
            "output_1048.txt: 0.0485\n",
            "output_785.txt: 0.0477\n",
            "output_1143.txt: 0.0472\n",
            "output_359.txt: 0.0466\n",
            "output_808.txt: 0.0466\n",
            "output_694.txt: 0.0465\n",
            "output_1463.txt: 0.0464\n",
            "output_96.txt: 0.0461\n",
            "output_180.txt: 0.0456\n",
            "output_350.txt: 0.0455\n",
            "output_564.txt: 0.0452\n",
            "output_122.txt: 0.0449\n",
            "output_212.txt: 0.0441\n",
            "output_451.txt: 0.0441\n",
            "output_73.txt: 0.0440\n",
            "output_976.txt: 0.0437\n",
            "output_841.txt: 0.0434\n",
            "output_1490.txt: 0.0430\n",
            "output_303.txt: 0.0430\n",
            "output_323.txt: 0.0429\n",
            "output_210.txt: 0.0426\n",
            "output_8.txt: 0.0426\n",
            "output_1123.txt: 0.0424\n",
            "output_730.txt: 0.0421\n",
            "output_915.txt: 0.0419\n",
            "output_131.txt: 0.0418\n",
            "output_1414.txt: 0.0418\n",
            "output_862.txt: 0.0415\n",
            "output_1194.txt: 0.0412\n",
            "output_1366.txt: 0.0410\n",
            "output_1517.txt: 0.0404\n",
            "output_1373.txt: 0.0401\n",
            "output_413.txt: 0.0400\n",
            "output_886.txt: 0.0400\n",
            "output_13.txt: 0.0397\n",
            "output_885.txt: 0.0395\n",
            "output_1442.txt: 0.0392\n",
            "output_1471.txt: 0.0392\n",
            "output_7.txt: 0.0392\n",
            "output_883.txt: 0.0392\n",
            "output_643.txt: 0.0391\n",
            "output_142.txt: 0.0390\n",
            "output_163.txt: 0.0390\n",
            "output_48.txt: 0.0389\n",
            "output_6.txt: 0.0389\n",
            "output_17.txt: 0.0388\n",
            "output_752.txt: 0.0387\n",
            "output_392.txt: 0.0386\n",
            "output_1466.txt: 0.0385\n",
            "output_1197.txt: 0.0383\n",
            "output_332.txt: 0.0382\n",
            "output_1259.txt: 0.0381\n",
            "output_1105.txt: 0.0380\n",
            "output_1005.txt: 0.0379\n",
            "output_207.txt: 0.0378\n",
            "output_319.txt: 0.0378\n",
            "output_549.txt: 0.0378\n",
            "output_889.txt: 0.0377\n",
            "output_471.txt: 0.0376\n",
            "output_1118.txt: 0.0375\n",
            "output_1189.txt: 0.0375\n",
            "output_894.txt: 0.0375\n",
            "output_1537.txt: 0.0374\n",
            "output_954.txt: 0.0373\n",
            "output_1412.txt: 0.0373\n",
            "output_563.txt: 0.0372\n",
            "output_37.txt: 0.0371\n",
            "output_1290.txt: 0.0370\n",
            "output_446.txt: 0.0369\n",
            "output_260.txt: 0.0369\n",
            "output_781.txt: 0.0369\n",
            "output_1269.txt: 0.0368\n",
            "output_579.txt: 0.0367\n",
            "output_1501.txt: 0.0367\n",
            "output_790.txt: 0.0366\n",
            "output_1058.txt: 0.0363\n",
            "output_224.txt: 0.0363\n",
            "output_72.txt: 0.0362\n",
            "output_517.txt: 0.0362\n",
            "output_218.txt: 0.0361\n",
            "output_1231.txt: 0.0360\n",
            "output_1152.txt: 0.0359\n",
            "output_1213.txt: 0.0359\n",
            "output_1426.txt: 0.0359\n",
            "output_677.txt: 0.0359\n",
            "output_361.txt: 0.0359\n",
            "output_233.txt: 0.0358\n",
            "output_812.txt: 0.0358\n",
            "output_675.txt: 0.0358\n",
            "output_1497.txt: 0.0358\n",
            "output_864.txt: 0.0358\n",
            "output_118.txt: 0.0356\n",
            "output_487.txt: 0.0356\n",
            "output_1040.txt: 0.0355\n",
            "output_1044.txt: 0.0355\n",
            "output_1443.txt: 0.0355\n",
            "output_691.txt: 0.0353\n",
            "output_354.txt: 0.0353\n",
            "output_823.txt: 0.0353\n",
            "output_1406.txt: 0.0353\n",
            "output_1310.txt: 0.0352\n",
            "output_551.txt: 0.0352\n",
            "output_1097.txt: 0.0352\n",
            "output_1364.txt: 0.0351\n",
            "output_404.txt: 0.0351\n",
            "output_2.txt: 0.0350\n",
            "output_147.txt: 0.0350\n",
            "output_1200.txt: 0.0349\n",
            "output_519.txt: 0.0348\n",
            "output_463.txt: 0.0348\n",
            "output_1305.txt: 0.0347\n",
            "output_953.txt: 0.0347\n",
            "output_825.txt: 0.0345\n",
            "output_999.txt: 0.0345\n",
            "output_603.txt: 0.0345\n",
            "output_1437.txt: 0.0343\n",
            "output_47.txt: 0.0343\n",
            "output_608.txt: 0.0343\n",
            "output_949.txt: 0.0343\n",
            "output_68.txt: 0.0342\n",
            "output_23.txt: 0.0341\n",
            "output_129.txt: 0.0340\n",
            "output_304.txt: 0.0339\n",
            "output_732.txt: 0.0339\n",
            "output_550.txt: 0.0337\n",
            "output_454.txt: 0.0337\n",
            "output_573.txt: 0.0337\n",
            "output_1178.txt: 0.0337\n",
            "output_453.txt: 0.0336\n",
            "output_197.txt: 0.0336\n",
            "output_788.txt: 0.0336\n",
            "output_1286.txt: 0.0335\n",
            "output_126.txt: 0.0335\n",
            "output_548.txt: 0.0334\n",
            "output_1055.txt: 0.0334\n",
            "output_972.txt: 0.0334\n",
            "output_16.txt: 0.0332\n",
            "output_201.txt: 0.0330\n",
            "output_1480.txt: 0.0330\n",
            "output_768.txt: 0.0330\n",
            "output_1543.txt: 0.0327\n",
            "output_150.txt: 0.0327\n",
            "output_45.txt: 0.0325\n",
            "output_1191.txt: 0.0323\n",
            "output_1106.txt: 0.0323\n",
            "output_1007.txt: 0.0322\n",
            "output_1552.txt: 0.0322\n",
            "output_112.txt: 0.0321\n",
            "output_729.txt: 0.0321\n",
            "output_817.txt: 0.0320\n",
            "output_1062.txt: 0.0320\n",
            "output_1124.txt: 0.0320\n",
            "output_935.txt: 0.0318\n",
            "output_1264.txt: 0.0316\n",
            "output_1260.txt: 0.0316\n",
            "output_1383.txt: 0.0316\n",
            "output_850.txt: 0.0315\n",
            "output_746.txt: 0.0315\n",
            "output_374.txt: 0.0314\n",
            "output_1376.txt: 0.0314\n",
            "output_1482.txt: 0.0313\n",
            "output_635.txt: 0.0313\n",
            "output_854.txt: 0.0311\n",
            "output_466.txt: 0.0311\n",
            "output_242.txt: 0.0309\n",
            "output_1502.txt: 0.0309\n",
            "output_496.txt: 0.0307\n",
            "output_167.txt: 0.0305\n",
            "output_1321.txt: 0.0304\n",
            "output_814.txt: 0.0301\n",
            "output_339.txt: 0.0301\n",
            "output_1534.txt: 0.0300\n",
            "output_748.txt: 0.0299\n",
            "output_367.txt: 0.0298\n",
            "output_702.txt: 0.0298\n",
            "output_101.txt: 0.0298\n",
            "output_448.txt: 0.0298\n",
            "output_831.txt: 0.0296\n",
            "output_1137.txt: 0.0295\n",
            "output_461.txt: 0.0295\n",
            "output_1163.txt: 0.0295\n",
            "output_1161.txt: 0.0295\n",
            "output_222.txt: 0.0295\n",
            "output_157.txt: 0.0294\n",
            "output_1249.txt: 0.0289\n",
            "output_389.txt: 0.0289\n",
            "output_1226.txt: 0.0288\n",
            "output_774.txt: 0.0284\n",
            "output_1103.txt: 0.0282\n",
            "output_1440.txt: 0.0279\n",
            "output_62.txt: 0.0275\n",
            "output_621.txt: 0.0271\n",
            "output_387.txt: 0.0264\n",
            "output_699.txt: 0.0264\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import math\n",
        "\n",
        "# Load the inverted index from its location\n",
        "inverted_index_path = '/content/drive/My Drive/inverted_index.json'\n",
        "with open(inverted_index_path, 'r', encoding='utf-8') as index_file:\n",
        "    inverted_index = json.load(index_file)\n",
        "\n",
        "doc_lengths = {}\n",
        "\n",
        "# Calculate document lengths\n",
        "for term, doc_dict in inverted_index.items():\n",
        "    for doc, positions in doc_dict.items():\n",
        "        if doc not in doc_lengths:\n",
        "            doc_lengths[doc] = len(positions)\n",
        "        else:\n",
        "            doc_lengths[doc] += len(positions)\n",
        "total_docs = len(doc_lengths)\n",
        "\n",
        "def calculate_tf(term, doc):\n",
        "    term_count = len(inverted_index[term][doc])\n",
        "    return (1 + math.log(term_count)) / (1 + math.log(doc_lengths[doc]))\n",
        "\n",
        "# Function to calculate inverse document frequency (IDF)\n",
        "def calculate_idf(term):\n",
        "    doc_count = len(inverted_index[term])\n",
        "    return math.log((total_docs + 1) / (doc_count + 1)) + 1\n",
        "\n",
        "# Function to handle phrase queries using positional data\n",
        "def check_phrase_in_document(query_tokens, doc, inverted_index):\n",
        "    \"\"\"Check if query tokens appear as a consecutive phrase in the document.\"\"\"\n",
        "    positions_list = [inverted_index[token][doc] for token in query_tokens if token in inverted_index and doc in inverted_index[token]]\n",
        "\n",
        "    if not positions_list or len(positions_list) != len(query_tokens):\n",
        "        return False\n",
        "\n",
        "    # Check for consecutive positions\n",
        "    for start_pos in positions_list[0]:\n",
        "        match = True\n",
        "        for i in range(1, len(positions_list)):\n",
        "            if (start_pos + i) not in positions_list[i]:\n",
        "                match = False\n",
        "                break\n",
        "        if match:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# Function to handle phrase queries\n",
        "def score_phrase_query(query_tokens, inverted_index):\n",
        "    relevant_docs = []\n",
        "    for doc in doc_lengths.keys():\n",
        "        if check_phrase_in_document(query_tokens, doc, inverted_index):\n",
        "            relevant_docs.append(doc)\n",
        "    return relevant_docs\n",
        "\n",
        "\n",
        "def calculate_vector_magnitude(vector):\n",
        "    \"\"\"Calculate the magnitude of a vector for normalization.\"\"\"\n",
        "    return math.sqrt(sum([value ** 2 for value in vector]))\n",
        "\n",
        "def score_documents(query_tokens, inverted_index):\n",
        "    scores = {}\n",
        "    query_term_weights = {}\n",
        "    query_vector_magnitude = 0\n",
        "\n",
        "    # Calculate IDF for query terms and build the query vector\n",
        "    for term in set(query_tokens):\n",
        "        if term in inverted_index:\n",
        "            idf = calculate_idf(term)\n",
        "            query_term_weights[term] = idf\n",
        "            query_vector_magnitude += idf ** 2\n",
        "\n",
        "    query_vector_magnitude = math.sqrt(query_vector_magnitude)\n",
        "\n",
        "    for term in query_tokens:\n",
        "        if term in inverted_index:\n",
        "            idf = query_term_weights[term]\n",
        "            for doc in inverted_index[term]:\n",
        "                tf = calculate_tf(term, doc)\n",
        "                tf_idf = tf * idf\n",
        "                if doc not in scores:\n",
        "                    scores[doc] = tf_idf ** 2\n",
        "                else:\n",
        "                    scores[doc] += tf_idf ** 2\n",
        "\n",
        "    # Normalize document scores\n",
        "    for doc in scores:\n",
        "        doc_vector_magnitude = calculate_vector_magnitude([calculate_tf(term, doc) * query_term_weights[term] for term in query_tokens if term in inverted_index and doc in inverted_index[term]])\n",
        "        if doc_vector_magnitude != 0 and query_vector_magnitude != 0:\n",
        "            scores[doc] = scores[doc] / (doc_vector_magnitude * query_vector_magnitude)\n",
        "\n",
        "    return sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "\n",
        "query = \"types of road hugger tires\"\n",
        "\n",
        "#query = pd.read_csv('/content/drive/My Drive/small_queries.csv')\n",
        "\n",
        "query_tokens = preprocess_text(query)\n",
        "results = score_documents(query_tokens, inverted_index)\n",
        "\n",
        "if results:\n",
        "    print(f\"Ranked documents for the query '{query}':\")\n",
        "    for doc, score in results:\n",
        "        print(f\"{doc}: {score:.4f}\")\n",
        "else:\n",
        "    print(f\"No documents found for the query '{query}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import math\n",
        "\n",
        "# Load the inverted index\n",
        "inverted_index_path = '/content/drive/My Drive/inverted_index.json'\n",
        "with open(inverted_index_path, 'r', encoding='utf-8') as index_file:\n",
        "    inverted_index = json.load(index_file)\n",
        "\n",
        "# Calculate document lengths (if not already done earlier)\n",
        "doc_lengths = {}\n",
        "for term, doc_dict in inverted_index.items():\n",
        "    for doc, positions in doc_dict.items():\n",
        "        if doc not in doc_lengths:\n",
        "            doc_lengths[doc] = len(positions)\n",
        "        else:\n",
        "            doc_lengths[doc] += len(positions)\n",
        "total_docs = len(doc_lengths)\n",
        "\n",
        "# Functions for TF, IDF, scoring, etc. (use your defined functions)\n",
        "\n",
        "# Load the CSV file containing the test queries\n",
        "queries_df = pd.read_csv('/content/drive/My Drive/small_queries.csv')\n",
        "\n",
        "all_queries_results = {}\n",
        "\n",
        "# Process each query and retrieve the top 10 documents\n",
        "for index, row in queries_df.iterrows():\n",
        "    query_number = row['Query number']\n",
        "    query_text = row['Query']\n",
        "\n",
        "    query_tokens = preprocess_text(query_text)\n",
        "\n",
        "    results = score_documents(query_tokens, inverted_index)\n",
        "\n",
        "    # Store the top 10 results\n",
        "    all_queries_results[query_number] = [doc for doc, score in results[:10]]\n",
        "\n",
        "output_df = pd.DataFrame([\n",
        "    {'Query number': query_id, 'Document': doc}\n",
        "    for query_id, docs in all_queries_results.items()\n",
        "    for doc in docs\n",
        "])\n",
        "output_path = '/content/drive/My Drive/results.csv'\n",
        "output_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Test output saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mhy3cqM7pno",
        "outputId": "9727c383-01cc-4eb4-90ac-608eed3edaf0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test output saved to /content/drive/My Drive/results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "inverted_index_path = '/content/drive/My Drive/inverted_index.json'\n",
        "with open(inverted_index_path, 'r', encoding='utf-8') as index_file:\n",
        "    inverted_index = json.load(index_file)\n",
        "\n",
        "doc_lengths = {}\n",
        "\n",
        "for term, doc_dict in inverted_index.items():\n",
        "    for doc, positions in doc_dict.items():\n",
        "        if doc not in doc_lengths:\n",
        "            doc_lengths[doc] = len(positions)\n",
        "        else:\n",
        "            doc_lengths[doc] += len(positions)\n",
        "\n",
        "total_docs = len(doc_lengths)\n",
        "def calculate_tf(term, doc):\n",
        "    term_count = len(inverted_index[term][doc])\n",
        "    return (1 + math.log(term_count)) / (1 + math.log(doc_lengths[doc]))\n",
        "# Function to calculate inverse document frequency (IDF)\n",
        "def calculate_idf(term):\n",
        "    doc_count = len(inverted_index[term])\n",
        "    return math.log((total_docs + 1) / (doc_count + 1)) + 1\n",
        "\n",
        "# Function to calculate vector magnitude for normalization\n",
        "def calculate_vector_magnitude(vector):\n",
        "    return math.sqrt(sum([value ** 2 for value in vector]))\n",
        "\n",
        "# Function to score documents using TF-IDF with cosine normalization\n",
        "def score_documents(query_tokens, inverted_index):\n",
        "    scores = {}\n",
        "    query_term_weights = {}\n",
        "    query_vector_magnitude = 0\n",
        "\n",
        "    # Calculate IDF for query terms and build the query vector\n",
        "    for term in set(query_tokens):\n",
        "        if term in inverted_index:\n",
        "            idf = calculate_idf(term)\n",
        "            query_term_weights[term] = idf\n",
        "            query_vector_magnitude += idf ** 2\n",
        "\n",
        "    query_vector_magnitude = math.sqrt(query_vector_magnitude)\n",
        "\n",
        "    for term in query_tokens:\n",
        "        if term in inverted_index:\n",
        "            idf = query_term_weights[term]\n",
        "            for doc in inverted_index[term]:\n",
        "                tf = calculate_tf(term, doc)\n",
        "                tf_idf = tf * idf\n",
        "                if doc not in scores:\n",
        "                    scores[doc] = tf_idf ** 2\n",
        "                else:\n",
        "                    scores[doc] += tf_idf ** 2\n",
        "\n",
        "    # Normalize document scores\n",
        "    for doc in scores:\n",
        "        doc_vector_magnitude = calculate_vector_magnitude([\n",
        "            calculate_tf(term, doc) * query_term_weights[term]\n",
        "            for term in query_tokens if term in inverted_index and doc in inverted_index[term]\n",
        "        ])\n",
        "        if doc_vector_magnitude != 0 and query_vector_magnitude != 0:\n",
        "            scores[doc] = scores[doc] / (doc_vector_magnitude * query_vector_magnitude)\n",
        "\n",
        "    return sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# Function to calculate Precision at K (P@K)\n",
        "def precision_at_k(retrieved_docs, relevant_docs, k):\n",
        "    retrieved_k = retrieved_docs[:k]\n",
        "    relevant_count = sum([1 for doc in retrieved_k if doc in relevant_docs])\n",
        "    return relevant_count / k\n",
        "\n",
        "# Function to calculate Recall at K (R@K)\n",
        "def recall_at_k(retrieved_docs, relevant_docs, k):\n",
        "    retrieved_k = retrieved_docs[:k]\n",
        "    relevant_count = sum([1 for doc in retrieved_k if doc in relevant_docs])\n",
        "    return relevant_count / len(relevant_docs) if len(relevant_docs) > 0 else 0\n",
        "\n",
        "# Function to calculate Mean Average Precision at K (MAP@K)\n",
        "def mean_average_precision_at_k(all_queries_results, all_queries_relevant_docs, k):\n",
        "    average_precisions = []\n",
        "    for query_id, retrieved_docs in all_queries_results.items():\n",
        "        relevant_docs = all_queries_relevant_docs.get(query_id, [])\n",
        "        precisions = [\n",
        "            precision_at_k(retrieved_docs, relevant_docs, i + 1)\n",
        "            for i in range(min(k, len(retrieved_docs)))\n",
        "            if retrieved_docs[i] in relevant_docs\n",
        "        ]\n",
        "        if precisions:\n",
        "            average_precisions.append(sum(precisions) / len(relevant_docs))\n",
        "    return sum(average_precisions) / len(average_precisions) if average_precisions else 0\n",
        "\n",
        "# Function to calculate Mean Average Recall at K (MAR@K)\n",
        "def mean_average_recall_at_k(all_queries_results, all_queries_relevant_docs, k):\n",
        "    recalls = []\n",
        "    for query_id, retrieved_docs in all_queries_results.items():\n",
        "        relevant_docs = all_queries_relevant_docs.get(query_id, [])\n",
        "        recall = recall_at_k(retrieved_docs, relevant_docs, k)\n",
        "        recalls.append(recall)\n",
        "    return sum(recalls) / len(recalls) if recalls else 0\n",
        "\n",
        "# Load the CSV file containing the queries (replace with your file path)\n",
        "queries_df = pd.read_csv('/content/drive/My Drive/small_queries.csv')  # Replace with your actual path\n",
        "\n",
        "\n",
        "# Load your result.csv containing the ground truth data\n",
        "ground_truth_path = ('/content/drive/My Drive/results.csv')  # Replace with your actual path\n",
        "ground_truth_df = pd.read_csv(ground_truth_path)\n",
        "\n",
        "# Create the ground truth dictionary\n",
        "all_queries_relevant_docs = {}\n",
        "for _, row in ground_truth_df.iterrows():\n",
        "    query_number = row['Query number']\n",
        "    document = row['Document']\n",
        "\n",
        "    if query_number not in all_queries_relevant_docs:\n",
        "        all_queries_relevant_docs[query_number] = [document]\n",
        "    else:\n",
        "        all_queries_relevant_docs[query_number].append(document)\n",
        "\n",
        "\n",
        "\n",
        "for index, row in queries_df.iterrows():\n",
        "    query_number = row['Query number']\n",
        "    query_text = row['Query']\n",
        "\n",
        "    # Preprocess the query text\n",
        "    query_tokens = preprocess_text(query_text)\n",
        "\n",
        "    # Get the ranked results for the query\n",
        "    results = score_documents(query_tokens, inverted_index)\n",
        "\n",
        "    # Store the top 10 results for each query\n",
        "    all_queries_results[query_number] = [doc for doc, score in results[:10]]\n",
        "\n",
        "# Compute MAP@3, MAP@10, MAR@3, MAR@10\n",
        "map_at_3 = mean_average_precision_at_k(all_queries_results, all_queries_relevant_docs, 3)\n",
        "map_at_10 = mean_average_precision_at_k(all_queries_results, all_queries_relevant_docs, 10)\n",
        "mar_at_3 = mean_average_recall_at_k(all_queries_results, all_queries_relevant_docs, 3)\n",
        "mar_at_10 = mean_average_recall_at_k(all_queries_results, all_queries_relevant_docs, 10)\n",
        "\n",
        "print(f\"MAP@3: {map_at_3:.4f}\")\n",
        "print(f\"MAP@10: {map_at_10:.4f}\")\n",
        "print(f\"MAR@3: {mar_at_3:.4f}\")\n",
        "print(f\"MAR@10: {mar_at_10:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJVCraZR_1lZ",
        "outputId": "1cace6aa-a29c-44ab-db1a-78c0621c4f39"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAP@3: 0.3205\n",
            "MAP@10: 1.0000\n",
            "MAR@3: 0.3179\n",
            "MAR@10: 0.9919\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}